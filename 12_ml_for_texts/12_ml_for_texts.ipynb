{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "from sklearn.dummy import DummyClassifier\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# читаем файл\n",
    "df = pd.read_csv('/datasets/toxic_comments.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# смотрим сверху\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# видим дисбаланс классов\n",
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d aww he matches this background colour i m se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i can t make any real suggestions on impr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation why the edits made under my userna...      0\n",
       "1  d aww he matches this background colour i m se...      0\n",
       "2  hey man i m really not trying to edit war it s...      0\n",
       "3  more i can t make any real suggestions on impr...      0\n",
       "4  you sir are my hero any chance you remember wh...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# лемматизируем\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df['text'] = df['text'].apply(lambda text : \n",
    "                             \" \".join(\n",
    "                                 re.sub(r'[^a-zA-Z]', ' ',\n",
    "                                        ''.join(lemmatizer.lemmatize(text.lower(), \n",
    "                                                                     get_wordnet_pos(text.lower())))).split()))\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выделяем признаки и целевую переменную\n",
    "X = df.drop(['toxic'], axis=1)\n",
    "y = df['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разбиваем на выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.4, \n",
    "                                                    random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# подгружаем стоп слова\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# векторизуем\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = count_tf_idf.fit_transform(X_train['text'].values)\n",
    "X_test = count_tf_idf.transform(X_test['text'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LogisticRegression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7656615546617725"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'C': 9}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 30s, sys: 4min 24s, total: 6min 55s\n",
      "Wall time: 6min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = {\n",
    "      'C': range(1,11)}\n",
    "\n",
    "\n",
    "estimator = LogisticRegression(random_state=12345, \n",
    "                               solver='liblinear', \n",
    "                               verbose = False, \n",
    "                               class_weight='balanced')\n",
    "\n",
    "model_lr = RandomizedSearchCV(estimator, \n",
    "                          param_grid,\n",
    "                          verbose = False,\n",
    "                          n_jobs=-1, \n",
    "                          scoring='f1', \n",
    "                          cv = 3)\n",
    "\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "display(model_lr.best_score_)\n",
    "\n",
    "display(model_lr.best_params_)\n",
    "\n",
    "best_model_lr = model_lr.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RandomForestClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36166749705173623"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 73, 'max_depth': 9}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 11s, sys: 1.22 s, total: 1min 12s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = {'n_estimators': range(1, 101), \n",
    "              'max_depth': range(1, 11)}\n",
    "\n",
    "\n",
    "estimator = RandomForestClassifier(random_state=12345, \n",
    "                                   n_jobs=-1,\n",
    "                                   verbose = False, \n",
    "                                   class_weight='balanced')\n",
    "\n",
    "model_rfc = RandomizedSearchCV(estimator, \n",
    "                          param_grid,\n",
    "                          verbose = False,\n",
    "                          n_jobs=-1, \n",
    "                          scoring='f1', \n",
    "                          cv = 3)\n",
    "\n",
    "model_rfc.fit(X_train, y_train)\n",
    "\n",
    "display(model_rfc.best_score_)\n",
    "\n",
    "display(model_rfc.best_params_)\n",
    "\n",
    "best_model_rfc = model_rfc.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DecisionTreeClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54588768659647"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 28s, sys: 1.72 s, total: 2min 30s\n",
      "Wall time: 2min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = {'max_depth': range(1, 11)}\n",
    "\n",
    "\n",
    "estimator = DecisionTreeClassifier(random_state=12345, \n",
    "                                   class_weight='balanced')\n",
    "\n",
    "model_dtc = RandomizedSearchCV(estimator, \n",
    "                          param_grid,\n",
    "                          verbose = False,\n",
    "                          n_jobs=-1, \n",
    "                          scoring='f1', \n",
    "                          cv = 3)\n",
    "\n",
    "model_dtc.fit(X_train, y_train)\n",
    "\n",
    "display(model_dtc.best_score_)\n",
    "\n",
    "display(model_dtc.best_params_)\n",
    "\n",
    "best_model_dtc = model_dtc.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучив три модели только логистическая регрессия смогла удовлетворить наши поотребности поставелнные в ТЗ. f1 > 0,75\n",
    "<br>ЗЫ на бустинговых моделях отлетало ядро**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18601870436008028"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# тест на адекватность\n",
    "preds_model_dr = np.ones(y_test.shape[0])\n",
    "f1_score(y_test, preds_model_dr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 для  Logistic Regression на тестовой выборке: 0.761690712680345\n"
     ]
    }
   ],
   "source": [
    "# резкльтат на тесте\n",
    "preds_model_lr = best_model_lr.predict(X_test)\n",
    "f1_model_lr = f1_score(y_test, preds_model_lr) \n",
    "print(\"f1 для  Logistic Regression на тестовой выборке:\", (f1_model_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как видим модель можно считать адекватной, а так же f1 на тесте больше 0.75, что не может не радовать**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Во время работы были проделаны следующий вещи:\n",
    "<br> 1) Рассмотрен набор данных, который был лемматизирован и векторизован\n",
    "<br> 2) Классы были не сбалансированны, поэтому при обученнии прибегали к балансировке классов\n",
    "<br> 3) Наиболее подходящей моделью обучения стала логичстическая регрессия\n",
    "<br> 4) Адекватность модели сравнивал с Dummy моделью** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1350,
    "start_time": "2023-05-27T09:11:34.830Z"
   },
   {
    "duration": 3,
    "start_time": "2023-05-27T09:11:38.985Z"
   },
   {
    "duration": 238,
    "start_time": "2023-05-27T09:11:39.992Z"
   },
   {
    "duration": 159,
    "start_time": "2023-05-27T09:11:45.701Z"
   },
   {
    "duration": 31,
    "start_time": "2023-05-27T09:12:03.885Z"
   },
   {
    "duration": 43,
    "start_time": "2023-05-27T09:12:11.605Z"
   },
   {
    "duration": 4325,
    "start_time": "2023-05-27T09:12:30.650Z"
   },
   {
    "duration": 30,
    "start_time": "2023-05-27T09:12:36.301Z"
   },
   {
    "duration": 32,
    "start_time": "2023-05-27T09:12:41.502Z"
   },
   {
    "duration": 5,
    "start_time": "2023-05-27T09:12:42.701Z"
   },
   {
    "duration": 6253,
    "start_time": "2023-05-27T09:12:46.030Z"
   },
   {
    "duration": 14,
    "start_time": "2023-05-27T09:12:54.256Z"
   },
   {
    "duration": 23,
    "start_time": "2023-05-27T09:12:58.326Z"
   },
   {
    "duration": 5,
    "start_time": "2023-05-27T09:13:11.330Z"
   },
   {
    "duration": 5,
    "start_time": "2023-05-27T09:13:13.046Z"
   },
   {
    "duration": 3,
    "start_time": "2023-05-27T09:13:17.300Z"
   },
   {
    "duration": 9820,
    "start_time": "2023-05-27T09:13:20.605Z"
   },
   {
    "duration": 2,
    "start_time": "2023-05-27T09:13:30.427Z"
   },
   {
    "duration": 1251,
    "start_time": "2023-05-27T09:14:13.486Z"
   },
   {
    "duration": 2,
    "start_time": "2023-05-27T09:14:14.739Z"
   },
   {
    "duration": 789,
    "start_time": "2023-05-27T09:14:14.742Z"
   },
   {
    "duration": 46,
    "start_time": "2023-05-27T09:14:15.532Z"
   },
   {
    "duration": 6,
    "start_time": "2023-05-27T09:14:15.580Z"
   },
   {
    "duration": 6024,
    "start_time": "2023-05-27T09:14:15.587Z"
   },
   {
    "duration": 8,
    "start_time": "2023-05-27T09:14:21.613Z"
   },
   {
    "duration": 23,
    "start_time": "2023-05-27T09:14:21.623Z"
   },
   {
    "duration": 163,
    "start_time": "2023-05-27T09:14:21.647Z"
   },
   {
    "duration": 3,
    "start_time": "2023-05-27T09:14:21.811Z"
   },
   {
    "duration": 9917,
    "start_time": "2023-05-27T09:14:21.815Z"
   },
   {
    "duration": 2,
    "start_time": "2023-05-27T09:14:31.734Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-27T09:17:41.592Z"
   },
   {
    "duration": 7,
    "start_time": "2023-05-28T09:44:52.660Z"
   },
   {
    "duration": 3,
    "start_time": "2023-05-28T09:44:56.819Z"
   },
   {
    "duration": 46,
    "start_time": "2023-05-28T09:45:20.384Z"
   },
   {
    "duration": 1398,
    "start_time": "2023-05-28T09:45:24.400Z"
   },
   {
    "duration": 2,
    "start_time": "2023-05-28T09:45:29.757Z"
   },
   {
    "duration": 2450,
    "start_time": "2023-05-28T09:45:29.980Z"
   },
   {
    "duration": 32,
    "start_time": "2023-05-28T09:45:32.432Z"
   },
   {
    "duration": 10,
    "start_time": "2023-05-28T09:45:32.465Z"
   },
   {
    "duration": 7076,
    "start_time": "2023-05-28T09:45:32.477Z"
   },
   {
    "duration": 8,
    "start_time": "2023-05-28T09:45:39.555Z"
   },
   {
    "duration": 35,
    "start_time": "2023-05-28T09:45:39.564Z"
   },
   {
    "duration": 215,
    "start_time": "2023-05-28T09:45:39.600Z"
   },
   {
    "duration": 3,
    "start_time": "2023-05-28T09:45:39.817Z"
   },
   {
    "duration": 11618,
    "start_time": "2023-05-28T09:45:39.821Z"
   },
   {
    "duration": 7,
    "start_time": "2023-05-28T09:45:51.441Z"
   },
   {
    "duration": 25,
    "start_time": "2023-05-28T09:45:51.450Z"
   },
   {
    "duration": 43946,
    "start_time": "2023-05-28T09:46:17.008Z"
   },
   {
    "duration": 388305,
    "start_time": "2023-05-28T09:54:50.365Z"
   },
   {
    "duration": 95,
    "start_time": "2023-05-28T10:01:18.672Z"
   },
   {
    "duration": 120191,
    "start_time": "2023-05-28T10:02:03.897Z"
   },
   {
    "duration": 172,
    "start_time": "2023-05-28T10:04:04.090Z"
   },
   {
    "duration": 15353,
    "start_time": "2023-05-28T10:05:21.858Z"
   },
   {
    "duration": 127,
    "start_time": "2023-05-28T10:51:21.615Z"
   },
   {
    "duration": 1461,
    "start_time": "2023-05-28T10:51:25.918Z"
   },
   {
    "duration": 2,
    "start_time": "2023-05-28T10:51:27.381Z"
   },
   {
    "duration": 2653,
    "start_time": "2023-05-28T10:51:27.384Z"
   },
   {
    "duration": 33,
    "start_time": "2023-05-28T10:51:30.038Z"
   },
   {
    "duration": 40,
    "start_time": "2023-05-28T10:51:30.072Z"
   },
   {
    "duration": 7625,
    "start_time": "2023-05-28T10:51:30.114Z"
   },
   {
    "duration": 19,
    "start_time": "2023-05-28T10:51:37.740Z"
   },
   {
    "duration": 22,
    "start_time": "2023-05-28T10:51:37.762Z"
   },
   {
    "duration": 218,
    "start_time": "2023-05-28T10:51:37.785Z"
   },
   {
    "duration": 3,
    "start_time": "2023-05-28T10:51:38.005Z"
   },
   {
    "duration": 12527,
    "start_time": "2023-05-28T10:51:38.009Z"
   },
   {
    "duration": 1399,
    "start_time": "2023-05-28T18:11:36.779Z"
   },
   {
    "duration": 3,
    "start_time": "2023-05-28T18:11:38.942Z"
   },
   {
    "duration": 2364,
    "start_time": "2023-05-28T18:11:39.177Z"
   },
   {
    "duration": 31,
    "start_time": "2023-05-28T18:11:41.542Z"
   },
   {
    "duration": 6,
    "start_time": "2023-05-28T18:11:41.574Z"
   },
   {
    "duration": 197,
    "start_time": "2023-05-28T18:12:25.281Z"
   },
   {
    "duration": 83,
    "start_time": "2023-05-28T18:12:34.461Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-28T18:15:24.558Z"
   },
   {
    "duration": 3,
    "start_time": "2023-05-28T18:15:26.997Z"
   },
   {
    "duration": 1438,
    "start_time": "2023-05-28T18:16:25.188Z"
   },
   {
    "duration": 3,
    "start_time": "2023-05-28T18:16:26.628Z"
   },
   {
    "duration": 1001,
    "start_time": "2023-05-28T18:16:26.632Z"
   },
   {
    "duration": 36,
    "start_time": "2023-05-28T18:16:27.635Z"
   },
   {
    "duration": 18,
    "start_time": "2023-05-28T18:16:27.674Z"
   },
   {
    "duration": 7632,
    "start_time": "2023-05-28T18:16:27.694Z"
   },
   {
    "duration": 10,
    "start_time": "2023-05-28T18:16:35.328Z"
   },
   {
    "duration": 64,
    "start_time": "2023-05-28T18:16:35.346Z"
   },
   {
    "duration": 144,
    "start_time": "2023-05-28T18:16:35.412Z"
   },
   {
    "duration": 3,
    "start_time": "2023-05-28T18:16:35.559Z"
   },
   {
    "duration": 12302,
    "start_time": "2023-05-28T18:16:35.564Z"
   },
   {
    "duration": 408604,
    "start_time": "2023-05-28T18:16:47.869Z"
   },
   {
    "duration": 141585,
    "start_time": "2023-05-28T18:23:36.476Z"
   },
   {
    "duration": 242,
    "start_time": "2023-05-28T18:25:58.063Z"
   },
   {
    "duration": 113,
    "start_time": "2023-05-28T18:29:20.204Z"
   },
   {
    "duration": 193059,
    "start_time": "2023-05-28T18:29:56.302Z"
   },
   {
    "duration": 11,
    "start_time": "2023-05-28T18:34:16.628Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-28T18:34:35.370Z"
   },
   {
    "duration": 21,
    "start_time": "2023-05-28T18:35:11.592Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-28T18:36:09.397Z"
   },
   {
    "duration": 12,
    "start_time": "2023-05-28T18:36:13.923Z"
   },
   {
    "duration": 24,
    "start_time": "2023-05-28T18:36:33.488Z"
   },
   {
    "duration": 33,
    "start_time": "2023-05-28T18:38:50.020Z"
   },
   {
    "duration": 15,
    "start_time": "2023-05-28T18:41:05.945Z"
   },
   {
    "duration": 13,
    "start_time": "2023-05-28T18:41:13.116Z"
   },
   {
    "duration": 6,
    "start_time": "2023-05-28T18:41:22.021Z"
   },
   {
    "duration": 28,
    "start_time": "2023-05-28T18:41:27.189Z"
   },
   {
    "duration": 24,
    "start_time": "2023-05-28T18:41:39.543Z"
   },
   {
    "duration": 40,
    "start_time": "2023-05-28T18:42:07.885Z"
   },
   {
    "duration": 41,
    "start_time": "2023-05-28T18:42:19.580Z"
   },
   {
    "duration": 29,
    "start_time": "2023-05-28T18:42:36.709Z"
   },
   {
    "duration": 29,
    "start_time": "2023-05-28T18:42:44.008Z"
   },
   {
    "duration": 33,
    "start_time": "2023-05-28T18:48:23.141Z"
   },
   {
    "duration": 27,
    "start_time": "2023-05-28T18:48:40.893Z"
   },
   {
    "duration": 40,
    "start_time": "2023-05-28T18:49:03.251Z"
   },
   {
    "duration": 52,
    "start_time": "2023-05-29T01:52:45.936Z"
   },
   {
    "duration": 1692,
    "start_time": "2023-05-29T01:52:52.356Z"
   },
   {
    "duration": 2429,
    "start_time": "2023-05-29T01:52:54.049Z"
   },
   {
    "duration": 36,
    "start_time": "2023-05-29T01:52:56.479Z"
   },
   {
    "duration": 10,
    "start_time": "2023-05-29T01:52:56.517Z"
   },
   {
    "duration": 448,
    "start_time": "2023-05-29T01:56:34.501Z"
   },
   {
    "duration": 322,
    "start_time": "2023-05-29T01:56:46.098Z"
   },
   {
    "duration": 581,
    "start_time": "2023-05-29T01:57:06.527Z"
   },
   {
    "duration": 413,
    "start_time": "2023-05-29T01:57:13.299Z"
   },
   {
    "duration": 55,
    "start_time": "2023-05-29T01:58:33.477Z"
   },
   {
    "duration": 297,
    "start_time": "2023-05-29T01:58:36.369Z"
   },
   {
    "duration": 1247,
    "start_time": "2023-05-29T01:59:05.262Z"
   },
   {
    "duration": 126,
    "start_time": "2023-05-29T01:59:06.511Z"
   },
   {
    "duration": 818,
    "start_time": "2023-05-29T01:59:06.638Z"
   },
   {
    "duration": 32,
    "start_time": "2023-05-29T01:59:07.457Z"
   },
   {
    "duration": 6,
    "start_time": "2023-05-29T01:59:07.491Z"
   },
   {
    "duration": 44,
    "start_time": "2023-05-29T01:59:07.499Z"
   },
   {
    "duration": 563,
    "start_time": "2023-05-29T01:59:07.544Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-29T01:59:08.110Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-29T01:59:08.112Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-29T01:59:08.113Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-29T01:59:08.114Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-29T01:59:08.116Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-29T01:59:08.118Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-29T01:59:08.119Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-29T01:59:08.120Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-29T01:59:08.122Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-29T01:59:08.123Z"
   },
   {
    "duration": 5,
    "start_time": "2023-05-29T01:59:44.238Z"
   },
   {
    "duration": 1299,
    "start_time": "2023-05-29T01:59:50.193Z"
   },
   {
    "duration": 201,
    "start_time": "2023-05-29T01:59:51.494Z"
   },
   {
    "duration": 844,
    "start_time": "2023-05-29T01:59:51.696Z"
   },
   {
    "duration": 31,
    "start_time": "2023-05-29T01:59:52.542Z"
   },
   {
    "duration": 5,
    "start_time": "2023-05-29T01:59:52.575Z"
   },
   {
    "duration": 25,
    "start_time": "2023-05-29T01:59:52.581Z"
   },
   {
    "duration": 27258,
    "start_time": "2023-05-29T01:59:52.608Z"
   },
   {
    "duration": 10,
    "start_time": "2023-05-29T02:00:19.868Z"
   },
   {
    "duration": 32,
    "start_time": "2023-05-29T02:00:19.880Z"
   },
   {
    "duration": 11,
    "start_time": "2023-05-29T02:00:19.914Z"
   },
   {
    "duration": 3,
    "start_time": "2023-05-29T02:00:19.927Z"
   },
   {
    "duration": 85,
    "start_time": "2023-05-29T02:00:19.941Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-29T02:00:20.028Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-29T02:00:20.030Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-29T02:00:20.031Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-29T02:00:20.033Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-29T02:00:20.034Z"
   },
   {
    "duration": 6374,
    "start_time": "2023-05-29T02:01:58.440Z"
   },
   {
    "duration": 1279,
    "start_time": "2023-05-29T02:02:14.638Z"
   },
   {
    "duration": 161,
    "start_time": "2023-05-29T02:02:15.918Z"
   },
   {
    "duration": 803,
    "start_time": "2023-05-29T02:02:16.080Z"
   },
   {
    "duration": 34,
    "start_time": "2023-05-29T02:02:16.886Z"
   },
   {
    "duration": 20,
    "start_time": "2023-05-29T02:02:16.923Z"
   },
   {
    "duration": 28,
    "start_time": "2023-05-29T02:02:16.945Z"
   },
   {
    "duration": 28252,
    "start_time": "2023-05-29T02:02:16.974Z"
   },
   {
    "duration": 15,
    "start_time": "2023-05-29T02:02:45.227Z"
   },
   {
    "duration": 29,
    "start_time": "2023-05-29T02:02:45.244Z"
   },
   {
    "duration": 5,
    "start_time": "2023-05-29T02:02:45.275Z"
   },
   {
    "duration": 19,
    "start_time": "2023-05-29T02:02:45.281Z"
   },
   {
    "duration": 7168,
    "start_time": "2023-05-29T02:02:45.302Z"
   },
   {
    "duration": 415486,
    "start_time": "2023-05-29T02:02:52.472Z"
   },
   {
    "duration": 72806,
    "start_time": "2023-05-29T02:09:47.961Z"
   },
   {
    "duration": 150494,
    "start_time": "2023-05-29T02:11:00.769Z"
   },
   {
    "duration": 30,
    "start_time": "2023-05-29T02:13:31.265Z"
   },
   {
    "duration": 56,
    "start_time": "2023-05-29T02:13:31.300Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
